{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CSE 258, Fall 2018: Homework 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import urllib\n",
    "import scipy.optimize\n",
    "import random\n",
    "from collections import defaultdict\n",
    "import nltk\n",
    "import string\n",
    "from nltk.stem.porter import *\n",
    "from sklearn import linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parseDataFromFile(fname):\n",
    "  for l in open(fname):\n",
    "    yield eval(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = list(parseDataFromFile(\"beer_50000.json\"))[:5000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tasks\n",
    "#### Using the code provided on the webpage, read the first 5000 reviews from the corpus, and read the reviews without capitalization or punctuation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. How many unique bigrams are there amongst all of the reviews? List the 5 most-frequently-occurring bigrams along with their number of occurrences in the corpus (1 mark)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordCount = defaultdict(int)\n",
    "punctuation = set(string.punctuation)\n",
    "for d in data:\n",
    "  r = ''.join([c for c in d['review/text'].lower() if not c in punctuation])\n",
    "  k = r.split()\n",
    "  for i in range(1,len(k)):\n",
    "    wordCount[k[i-1]+' '+k[i]] += 1\n",
    "counts = [(wordCount[w], w) for w in wordCount]\n",
    "counts.sort()\n",
    "counts.reverse()\n",
    "\n",
    "words = [x[1] for x in counts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "182246"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(numpy.unique(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(4587, 'with a'),\n",
       " (2595, 'in the'),\n",
       " (2245, 'of the'),\n",
       " (2056, 'is a'),\n",
       " (2033, 'on the')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. The code provided performs least squares using the 1000 most common unigrams. Adapt it to use the 1000 most common bigrams and report the MSE obtained using the new predictor (use bigrams only, i.e., not unigrams+bigrams) (1 mark). Note that the code performs regularized regression with a regularization parameter of 1.0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordCount = defaultdict(int)\n",
    "punctuation = set(string.punctuation)\n",
    "for d in data:\n",
    "  r = ''.join([c for c in d['review/text'].lower() if not c in punctuation])\n",
    "  k = r.split()\n",
    "  for i in range(1,len(k)):\n",
    "    wordCount[k[i-1]+' '+k[i]] += 1\n",
    "\n",
    "counts = [(wordCount[w], w) for w in wordCount]\n",
    "counts.sort()\n",
    "counts.reverse()\n",
    "\n",
    "words = [x[1] for x in counts[:1000]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Sentiment analysis\n",
    "\n",
    "wordId = dict(zip(words, range(len(words))))\n",
    "wordSet = set(words)\n",
    "\n",
    "def feature(datum):\n",
    "  feat = [0]*len(words)\n",
    "  r = ''.join([c for c in datum['review/text'].lower() if not c in punctuation])\n",
    "  k = r.split()\n",
    "  for i in range(1,len(k)):\n",
    "    if (k[i-1]+' '+k[i]) in words:\n",
    "      feat[wordId[k[i-1]+' '+k[i]]] += 1\n",
    "  feat.append(1) #offset\n",
    "  return feat\n",
    "\n",
    "X = [feature(d) for d in data]\n",
    "y = [d['review/overall'] for d in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = linear_model.Ridge(1.0, fit_intercept=False)\n",
    "clf.fit(X, y)\n",
    "theta = clf.coef_\n",
    "predictions = clf.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.34315301406136334"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y,predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. What is the inverse document frequency of the words 'foam', 'smell', 'banana', 'lactic', and 'tart'? What are their tf-idf scores in the first review (using log base 10) (1 mark)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf(word, r):\n",
    "    count = 0\n",
    "    k = r.split()\n",
    "    m = collections.Counter(k)\n",
    "    count = m[word]\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def n_containing(word, bloblist):\n",
    "    count = 0\n",
    "    for l in bloblist:\n",
    "        if word in l.split():\n",
    "            count+=1\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def idf(word, bloblist):\n",
    "    if n_containing(word,bloblist) == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return math.log10(len(bloblist) / n_containing(word, bloblist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = []\n",
    "for l in data:\n",
    "    r = ''.join([c for c in l['review/text'].lower() if not c in punctuation])\n",
    "    reviews.append(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inverse document frequency of foam is 1.1378686206869628\n",
      "Inverse document frequency of smell is 0.5379016188648442\n",
      "Inverse document frequency of banana is 1.6777807052660807\n",
      "Inverse document frequency of lactic is 2.9208187539523753\n",
      "Inverse document frequency of tart is 1.8068754016455384\n"
     ]
    }
   ],
   "source": [
    "p = ['foam','smell','banana','lactic','tart']\n",
    "for i in p:\n",
    "    print('Inverse document frequency of ' + i + ' is ' + str(idf(i, reviews)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In first review, tf-idf score of foam is 2.2757372413739256\n",
      "In first review, tf-idf score of smell is 0.5379016188648442\n",
      "In first review, tf-idf score of banana is 3.3555614105321614\n",
      "In first review, tf-idf score of lactic is 5.841637507904751\n",
      "In first review, tf-idf score of tart is 1.8068754016455384\n"
     ]
    }
   ],
   "source": [
    "for i in p:\n",
    "    print('In first review, tf-idf score of ' + i + ' is ' + str(tf(i,reviews[0])*idf(i,reviews)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. What is the cosine similarity between the first and the second review in terms of their tf-idf representations (considering unigrams only) (1 mark)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "k1 = reviews[0].split()\n",
    "tfidf1 = defaultdict(int)\n",
    "for i in k1:\n",
    "    tfidf1[i]=tf(i,reviews[0])*idf(i,reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "k2 = reviews[1].split()\n",
    "tfidf2 = defaultdict(int)\n",
    "for i in k2:\n",
    "    tfidf2[i]=tf(i,reviews[1])*idf(i,reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "intersection = set(tfidf1.keys()) & set(tfidf2.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum1 = sum([tfidf1[x]**2 for x in tfidf1.keys()])\n",
    "sum2 = sum([tfidf2[x]**2 for x in tfidf2.keys()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = sum([tfidf1[x] * tfidf2[x] for x in intersection])/(math.sqrt(sum1) * \\\n",
    "                                                        math.sqrt(sum2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The cosine similarity between the first and the second review is 0.0658819397474438.\n"
     ]
    }
   ],
   "source": [
    "print('The cosine similarity between the first and the second review is ' + \\\n",
    "      str(k) + '.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Which other review has the highest cosine similarity compared to the first review (provide the beerId and profileName, or the text of the review) (1 mark)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordlist =[]\n",
    "for i in reviews:\n",
    "    r =i.split()\n",
    "    for k in r:\n",
    "        wordlist.append(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordSet = set(wordlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computetf(review):\n",
    "    tfdict = dict.fromkeys(wordSet, 0)\n",
    "    worddict = dict.fromkeys(wordSet, 0)\n",
    "    r = review.split()\n",
    "    for word in r:\n",
    "        worddict[word]+=1\n",
    "    for word in r:\n",
    "        tfdict[word] = worddict[word]\n",
    "    return tfdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = dict.fromkeys(wordSet, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "for l in reviews:\n",
    "    r = l.split()\n",
    "    for word in wordSet:\n",
    "        if word in r:\n",
    "            count[word] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "idf = {}\n",
    "for key in count:\n",
    "    idf[key] = math.log10(5000/count[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute tfidf in the first review\n",
    "k = reviews[0].split()\n",
    "l = computetf(reviews[0])\n",
    "k = set(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = dict.fromkeys(wordSet, 0)\n",
    "for word in k:\n",
    "    tfidf[word] = l[word] * idf[word]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim = []\n",
    "for i in reviews[1:]:\n",
    "    q = set(i.split())\n",
    "    l = computetf(i)\n",
    "    tfidftest = dict.fromkeys(wordSet, 0)\n",
    "    for word in q:\n",
    "        tfidftest[word] = l[word] * idf[word]\n",
    "    intersection = set(tfidf.keys()) & set(tfidftest.keys())\n",
    "    sum1 = sum([tfidf[x]**2 for x in tfidf.keys()])\n",
    "    sum2 = sum([tfidftest[x]**2 for x in tfidftest.keys()])\n",
    "    p = math.sqrt(sum1) * math.sqrt(sum2)\n",
    "    if p == 0:\n",
    "        sim.append(0)\n",
    "    else:\n",
    "        k = sum([tfidf[x] * tfidftest[x] for x in intersection])/p\n",
    "        sim.append(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2968679537499197"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2342"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim.index(max(sim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'72146'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[2343]['beer/beerId']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. Adapt the original model that uses the 1000 most common unigrams, but replace the features with their 1000-dimensional tf-idf representations, and report the MSE obtained with the new model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordCount = defaultdict(int)\n",
    "punctuation = set(string.punctuation)\n",
    "for d in data:\n",
    "  r = ''.join([c for c in d['review/text'].lower() if not c in punctuation])\n",
    "  for w in r.split():\n",
    "    wordCount[w] += 1\n",
    "\n",
    "counts = [(wordCount[w], w) for w in wordCount]\n",
    "counts.sort()\n",
    "counts.reverse()\n",
    "\n",
    "words = [x[1] for x in counts[:1000]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordId = dict(zip(words, range(len(words))))\n",
    "\n",
    "\n",
    "def feature(datum):\n",
    "  feat = [0]*len(words)\n",
    "  r = ''.join([c for c in datum['review/text'].lower() if not c in punctuation])\n",
    "  tfidftest = dict.fromkeys(wordSet, 0)\n",
    "  l = computetf(r)\n",
    "  for w in r.split():\n",
    "      tfidftest[w] = l[w] * idf[w]\n",
    "      if w in words:\n",
    "          feat[wordId[w]] = tfidftest[w]\n",
    "  feat.append(1) #offset\n",
    "  return feat\n",
    "\n",
    "X = [feature(d) for d in data]\n",
    "y = [d['review/overall'] for d in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = linear_model.Ridge(1.0, fit_intercept=False)\n",
    "clf.fit(X, y)\n",
    "theta = clf.coef_\n",
    "predictions = clf.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.27875956007772185"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7. Implement a validation pipeline for this same data, by randomly shuffling the data, using 5000 reviews for training, another 5000 for validation, and another 5000 for testing. Consider regularization parameters in the range {0.01, 0.1, 1, 10, 100}, and report MSEs on the test set for the model that performs best on the validation set. Using this pipeline, compare the following alternatives in terms of their performance:\n",
    "#### Unigrams vs. bigrams\n",
    "#### Removing punctuation vs. preserving it. The model that preserves punctuation should treat punctuation characters as separate words, e.g. \"\\Amazing!\" would become ['amazing', '!']\n",
    "#### tfidf vs. word counts\n",
    "#### In total you should compare 2 * 2 * 2 = 8 models, and produce a table comparing their performance (2 marks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "wholedata = list(parseDataFromFile(\"beer_50000.json\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_shuffle = shuffle(wholedata, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "training = data_shuffle[:5000]\n",
    "validation = data_shuffle[5000:10000]\n",
    "testing = data_shuffle[10000:15000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#unigram+ remove punctuation + tfidf\n",
    "wordCount = defaultdict(int)\n",
    "punctuation = set(string.punctuation)\n",
    "for d in wholedata:\n",
    "    r = ''.join([c for c in d['review/text'].lower() if not c in punctuation])\n",
    "    for w in r.split():\n",
    "        wordCount[w] += 1\n",
    "\n",
    "counts = [(wordCount[w], w) for w in wordCount]\n",
    "counts.sort()\n",
    "counts.reverse()\n",
    "\n",
    "words = [x[1] for x in counts[:1000]]\n",
    "\n",
    "def abc(dataset):\n",
    "    reviews = []\n",
    "    for l in dataset:\n",
    "        r = ''.join([c for c in l['review/text'].lower() if not c in punctuation])\n",
    "        reviews.append(r)\n",
    "    \n",
    "    wordlist =[]\n",
    "    for i in reviews:\n",
    "        r =i.split()\n",
    "        for k in r:\n",
    "            wordlist.append(k)\n",
    "    wordSet = set(wordlist)\n",
    "    \n",
    "    def computetf(review):\n",
    "        tfdict = dict.fromkeys(wordSet, 0)\n",
    "        worddict = dict.fromkeys(wordSet, 0)\n",
    "        r = review.split()\n",
    "        for word in r:\n",
    "            worddict[word]+=1\n",
    "        for word in r:\n",
    "            tfdict[word] = worddict[word]\n",
    "        return tfdict\n",
    "    \n",
    "    count = dict.fromkeys(wordSet, 0)\n",
    "    for l in reviews:\n",
    "        r = l.split()\n",
    "        for word in wordSet:\n",
    "            if word in r:\n",
    "                count[word] += 1\n",
    "    \n",
    "    idf = {}\n",
    "    for key in count:\n",
    "        idf[key] = math.log10(5000/count[key])\n",
    "    \n",
    "    wordId = dict(zip(words, range(len(words))))\n",
    "\n",
    "    def feature(datum):\n",
    "      feat = [0]*len(words)\n",
    "      r = ''.join([c for c in datum['review/text'].lower() if not c in punctuation])\n",
    "      tfidftest = dict.fromkeys(wordSet, 0)\n",
    "      l = computetf(r)\n",
    "      for w in r.split():\n",
    "          tfidftest[w] = l[w] * idf[w]\n",
    "          if w in words:\n",
    "              feat[wordId[w]] = tfidftest[w]\n",
    "      feat.append(1) #offset\n",
    "      return feat\n",
    "                \n",
    "    X = [feature(d) for d in dataset]\n",
    "    y = [d['review/overall'] for d in dataset]\n",
    "    return X,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,y_train = abc(training)\n",
    "X_valid,y_valid = abc(validation)\n",
    "X_test,y_test = abc(testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3986589211029011\n",
      "0.3985506569923159\n",
      "0.39763546672588973\n",
      "0.39197566669507206\n",
      "0.4105118967587855\n"
     ]
    }
   ],
   "source": [
    "para = [0.01, 0.1, 1, 10, 100]\n",
    "for i in para:\n",
    "    clf = linear_model.Ridge(i, fit_intercept=False)\n",
    "    clf.fit(X_train, y_train)\n",
    "    theta = clf.coef_\n",
    "    predictions = clf.predict(X_valid)\n",
    "    print(mean_squared_error(y_valid, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#select 10\n",
    "clf = linear_model.Ridge(10, fit_intercept=False)\n",
    "clf.fit(X_train, y_train)\n",
    "theta = clf.coef_\n",
    "predictions = clf.predict(X_test)\n",
    "un_re_tfidf = mean_squared_error(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#unigram + remove punctuation + wordCount\n",
    "wordCount = defaultdict(int)\n",
    "punctuation = set(string.punctuation)\n",
    "for d in wholedata:\n",
    "    r = ''.join([c for c in d['review/text'].lower() if not c in punctuation])\n",
    "    for w in r.split():\n",
    "        wordCount[w] += 1\n",
    "\n",
    "counts = [(wordCount[w], w) for w in wordCount]\n",
    "counts.sort()\n",
    "counts.reverse()\n",
    "\n",
    "words = [x[1] for x in counts[:1000]]\n",
    "\n",
    "def qwe(dataset):\n",
    "    ### Sentiment analysis\n",
    "\n",
    "    wordId = dict(zip(words, range(len(words))))\n",
    "    wordSet = set(words)\n",
    "\n",
    "    def feature(datum):\n",
    "      feat = [0]*len(words)\n",
    "      r = ''.join([c for c in datum['review/text'].lower() if not c in punctuation])\n",
    "      for w in r.split():\n",
    "        if w in words:\n",
    "          feat[wordId[w]] += 1\n",
    "      feat.append(1) #offset\n",
    "      return feat\n",
    "\n",
    "    X = [feature(d) for d in dataset]\n",
    "    y = [d['review/overall'] for d in dataset]\n",
    "    return X,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,y_train = qwe(training)\n",
    "X_valid,y_valid = qwe(validation)\n",
    "X_test,y_test = qwe(testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3997975396787234\n",
      "0.3995938284487193\n",
      "0.3976329722324505\n",
      "0.38384042573876026\n",
      "0.40114684488089125\n"
     ]
    }
   ],
   "source": [
    "para = [0.01, 0.1, 1, 10, 100]\n",
    "for i in para:\n",
    "    clf = linear_model.Ridge(i, fit_intercept=False)\n",
    "    clf.fit(X_train, y_train)\n",
    "    theta = clf.coef_\n",
    "    predictions = clf.predict(X_valid)\n",
    "    print(mean_squared_error(y_valid, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#select 10\n",
    "clf = linear_model.Ridge(10, fit_intercept=False)\n",
    "clf.fit(X_train, y_train)\n",
    "theta = clf.coef_\n",
    "predictions = clf.predict(X_test)\n",
    "un_re_wc = mean_squared_error(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#unigram + preserve punctuation + wordCount\n",
    "wordCount = defaultdict(int)\n",
    "punctuation = set(string.punctuation)\n",
    "for d in wholedata:\n",
    "    r = ''.join([c for c in d['review/text'].lower()])\n",
    "    for w in r.split():\n",
    "        wordCount[w] += 1\n",
    "\n",
    "counts = [(wordCount[w], w) for w in wordCount]\n",
    "counts.sort()\n",
    "counts.reverse()\n",
    "\n",
    "words = [x[1] for x in counts[:1000]]\n",
    "\n",
    "def qwe(dataset):\n",
    "    ### Sentiment analysis\n",
    "\n",
    "    wordId = dict(zip(words, range(len(words))))\n",
    "    wordSet = set(words)\n",
    "\n",
    "    def feature(datum):\n",
    "      feat = [0]*len(words)\n",
    "      r = ''.join([c for c in datum['review/text'].lower()])\n",
    "      for w in r.split():\n",
    "        if w in words:\n",
    "          feat[wordId[w]] += 1\n",
    "      feat.append(1) #offset\n",
    "      return feat\n",
    "\n",
    "    X = [feature(d) for d in dataset]\n",
    "    y = [d['review/overall'] for d in dataset]\n",
    "    return X,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,y_train = qwe(training)\n",
    "X_valid,y_valid = qwe(validation)\n",
    "X_test,y_test = qwe(testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.44101397877820875\n",
      "0.4407646891754004\n",
      "0.4383794404862169\n",
      "0.4215491733753499\n",
      "0.42483820735502975\n"
     ]
    }
   ],
   "source": [
    "para = [0.01, 0.1, 1, 10, 100]\n",
    "for i in para:\n",
    "    clf = linear_model.Ridge(i, fit_intercept=False)\n",
    "    clf.fit(X_train, y_train)\n",
    "    theta = clf.coef_\n",
    "    predictions = clf.predict(X_valid)\n",
    "    print(mean_squared_error(y_valid, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#select 10\n",
    "clf = linear_model.Ridge(10, fit_intercept=False)\n",
    "clf.fit(X_train, y_train)\n",
    "theta = clf.coef_\n",
    "predictions = clf.predict(X_test)\n",
    "un_pr_wc = mean_squared_error(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#unigram+ preserve punctuation + tfidf\n",
    "wordCount = defaultdict(int)\n",
    "punctuation = set(string.punctuation)\n",
    "for d in wholedata:\n",
    "    r = ''.join([c for c in d['review/text'].lower()])\n",
    "    for w in r.split():\n",
    "        wordCount[w] += 1\n",
    "\n",
    "counts = [(wordCount[w], w) for w in wordCount]\n",
    "counts.sort()\n",
    "counts.reverse()\n",
    "\n",
    "words = [x[1] for x in counts[:1000]]\n",
    "\n",
    "def abc(dataset):\n",
    "    reviews = []\n",
    "    for l in dataset:\n",
    "        r = ''.join([c for c in l['review/text'].lower()])\n",
    "        reviews.append(r)\n",
    "    \n",
    "    wordlist =[]\n",
    "    for i in reviews:\n",
    "        r =i.split()\n",
    "        for k in r:\n",
    "            wordlist.append(k)\n",
    "    wordSet = set(wordlist)\n",
    "    \n",
    "    def computetf(review):\n",
    "        tfdict = dict.fromkeys(wordSet, 0)\n",
    "        worddict = dict.fromkeys(wordSet, 0)\n",
    "        r = review.split()\n",
    "        for word in r:\n",
    "            worddict[word]+=1\n",
    "        for word in r:\n",
    "            tfdict[word] = worddict[word]\n",
    "        return tfdict\n",
    "    \n",
    "    count = dict.fromkeys(wordSet, 0)\n",
    "    for l in reviews:\n",
    "        r = l.split()\n",
    "        for word in wordSet:\n",
    "            if word in r:\n",
    "                count[word] += 1\n",
    "    \n",
    "    idf = {}\n",
    "    for key in count:\n",
    "        idf[key] = math.log10(5000/count[key])\n",
    "    \n",
    "    wordId = dict(zip(words, range(len(words))))\n",
    "\n",
    "    def feature(datum):\n",
    "      feat = [0]*len(words)\n",
    "      r = ''.join([c for c in datum['review/text'].lower()])\n",
    "      tfidftest = dict.fromkeys(wordSet, 0)\n",
    "      l = computetf(r)\n",
    "      for w in r.split():\n",
    "          tfidftest[w] = l[w] * idf[w]\n",
    "          if w in words:\n",
    "              feat[wordId[w]] = tfidftest[w]\n",
    "      feat.append(1) #offset\n",
    "      return feat\n",
    "                \n",
    "    X = [feature(d) for d in dataset]\n",
    "    y = [d['review/overall'] for d in dataset]\n",
    "    return X,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,y_train = abc(training)\n",
    "X_valid,y_valid = abc(validation)\n",
    "X_test,y_test = abc(testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.44000105219714086\n",
      "0.43987523794358513\n",
      "0.438776347186248\n",
      "0.4309630424068235\n",
      "0.440141292113085\n"
     ]
    }
   ],
   "source": [
    "para = [0.01, 0.1, 1, 10, 100]\n",
    "for i in para:\n",
    "    clf = linear_model.Ridge(i, fit_intercept=False)\n",
    "    clf.fit(X_train, y_train)\n",
    "    theta = clf.coef_\n",
    "    predictions = clf.predict(X_valid)\n",
    "    print(mean_squared_error(y_valid, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#select 10\n",
    "clf = linear_model.Ridge(10, fit_intercept=False)\n",
    "clf.fit(X_train, y_train)\n",
    "theta = clf.coef_\n",
    "predictions = clf.predict(X_test)\n",
    "un_pr_tfidf = mean_squared_error(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bigrams+ preserve punctuation + tfidf\n",
    "wordCount = defaultdict(int)\n",
    "punctuation = set(string.punctuation)\n",
    "for d in wholedata:\n",
    "  r = ''.join([c for c in d['review/text'].lower()])\n",
    "  k = r.split()\n",
    "  for i in range(1,len(k)):\n",
    "    wordCount[k[i-1]+' '+k[i]] += 1\n",
    "\n",
    "counts = [(wordCount[w], w) for w in wordCount]\n",
    "counts.sort()\n",
    "counts.reverse()\n",
    "\n",
    "words = [x[1] for x in counts[:1000]]\n",
    "\n",
    "def abc(dataset):\n",
    "    reviews = []\n",
    "    for l in dataset:\n",
    "        r = ''.join([c for c in l['review/text'].lower()])\n",
    "        reviews.append(r)\n",
    "    \n",
    "    wordlist =[]\n",
    "    for i in reviews:\n",
    "        r =i.split()\n",
    "        for k in r:\n",
    "            wordlist.append(k)\n",
    "    wordSet = set(wordlist)\n",
    "    \n",
    "    def computetf(review):\n",
    "        tfdict = dict.fromkeys(wordSet, 0)\n",
    "        worddict = dict.fromkeys(wordSet, 0)\n",
    "        r = review.split()\n",
    "        for word in r:\n",
    "            worddict[word]+=1\n",
    "        for word in r:\n",
    "            tfdict[word] = worddict[word]\n",
    "        return tfdict\n",
    "    \n",
    "    count = dict.fromkeys(wordSet, 0)\n",
    "    for l in reviews:\n",
    "        r = l.split()\n",
    "        for word in wordSet:\n",
    "            if word in r:\n",
    "                count[word] += 1\n",
    "    \n",
    "    idf = {}\n",
    "    for key in count:\n",
    "        idf[key] = math.log10(5000/count[key])\n",
    "    \n",
    "    wordId = dict(zip(words, range(len(words))))\n",
    "\n",
    "    def feature(datum):\n",
    "      feat = [0]*len(words)\n",
    "      r = ''.join([c for c in datum['review/text'].lower()])\n",
    "      tfidftest = dict.fromkeys(wordSet, 0)\n",
    "      l = computetf(r)\n",
    "      for w in r.split():\n",
    "          tfidftest[w] = l[w] * idf[w]\n",
    "          if w in words:\n",
    "              feat[wordId[w]] = tfidftest[w]\n",
    "      feat.append(1) #offset\n",
    "      return feat\n",
    "                \n",
    "    X = [feature(d) for d in dataset]\n",
    "    y = [d['review/overall'] for d in dataset]\n",
    "    return X,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,y_train = abc(training)\n",
    "X_valid,y_valid = abc(validation)\n",
    "X_test,y_test = abc(testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4657165521143806\n",
      "0.4657192764878528\n",
      "0.4657470490704898\n",
      "0.4660774478986139\n",
      "0.4744431468665896\n"
     ]
    }
   ],
   "source": [
    "para = [0.01, 0.1, 1, 10, 100]\n",
    "for i in para:\n",
    "    clf = linear_model.Ridge(i, fit_intercept=False)\n",
    "    clf.fit(X_train, y_train)\n",
    "    theta = clf.coef_\n",
    "    predictions = clf.predict(X_valid)\n",
    "    print(mean_squared_error(y_valid, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#select 0.01\n",
    "clf = linear_model.Ridge(0.01, fit_intercept=False)\n",
    "clf.fit(X_train, y_train)\n",
    "theta = clf.coef_\n",
    "predictions = clf.predict(X_test)\n",
    "bi_pr_tfidf = mean_squared_error(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bigrams+ remove punctuation + tfidf\n",
    "wordCount = defaultdict(int)\n",
    "punctuation = set(string.punctuation)\n",
    "for d in wholedata:\n",
    "  r = ''.join([c for c in d['review/text'].lower() if not c in punctuation])\n",
    "  k = r.split()\n",
    "  for i in range(1,len(k)):\n",
    "    wordCount[k[i-1]+' '+k[i]] += 1\n",
    "\n",
    "counts = [(wordCount[w], w) for w in wordCount]\n",
    "counts.sort()\n",
    "counts.reverse()\n",
    "\n",
    "words = [x[1] for x in counts[:1000]]\n",
    "\n",
    "def abc(dataset):\n",
    "    reviews = []\n",
    "    for l in dataset:\n",
    "        r = ''.join([c for c in l['review/text'].lower() if not c in punctuation])\n",
    "        reviews.append(r)\n",
    "    \n",
    "    wordlist =[]\n",
    "    for i in reviews:\n",
    "        r =i.split()\n",
    "        for k in r:\n",
    "            wordlist.append(k)\n",
    "    wordSet = set(wordlist)\n",
    "    \n",
    "    def computetf(review):\n",
    "        tfdict = dict.fromkeys(wordSet, 0)\n",
    "        worddict = dict.fromkeys(wordSet, 0)\n",
    "        r = review.split()\n",
    "        for word in r:\n",
    "            worddict[word]+=1\n",
    "        for word in r:\n",
    "            tfdict[word] = worddict[word]\n",
    "        return tfdict\n",
    "    \n",
    "    count = dict.fromkeys(wordSet, 0)\n",
    "    for l in reviews:\n",
    "        r = l.split()\n",
    "        for word in wordSet:\n",
    "            if word in r:\n",
    "                count[word] += 1\n",
    "    \n",
    "    idf = {}\n",
    "    for key in count:\n",
    "        idf[key] = math.log10(5000/count[key])\n",
    "    \n",
    "    wordId = dict(zip(words, range(len(words))))\n",
    "\n",
    "    def feature(datum):\n",
    "      feat = [0]*len(words)\n",
    "      r = ''.join([c for c in datum['review/text'].lower() if not c in punctuation])\n",
    "      tfidftest = dict.fromkeys(wordSet, 0)\n",
    "      l = computetf(r)\n",
    "      for w in r.split():\n",
    "          tfidftest[w] = l[w] * idf[w]\n",
    "          if w in words:\n",
    "              feat[wordId[w]] = tfidftest[w]\n",
    "      feat.append(1) #offset\n",
    "      return feat\n",
    "                \n",
    "    X = [feature(d) for d in dataset]\n",
    "    y = [d['review/overall'] for d in dataset]\n",
    "    return X,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,y_train = abc(training)\n",
    "X_valid,y_valid = abc(validation)\n",
    "X_test,y_test = abc(testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4657165521143806\n",
      "0.4657192764878528\n",
      "0.4657470490704898\n",
      "0.4660774478986139\n",
      "0.4744431468665896\n"
     ]
    }
   ],
   "source": [
    "para = [0.01, 0.1, 1, 10, 100]\n",
    "for i in para:\n",
    "    clf = linear_model.Ridge(i, fit_intercept=False)\n",
    "    clf.fit(X_train, y_train)\n",
    "    theta = clf.coef_\n",
    "    predictions = clf.predict(X_valid)\n",
    "    print(mean_squared_error(y_valid, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "#select 0.01\n",
    "clf = linear_model.Ridge(0.01, fit_intercept=False)\n",
    "clf.fit(X_train, y_train)\n",
    "theta = clf.coef_\n",
    "predictions = clf.predict(X_test)\n",
    "bi_re_tfidf = mean_squared_error(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bigrams+ remove punctuation + wordCount\n",
    "wordCount = defaultdict(int)\n",
    "punctuation = set(string.punctuation)\n",
    "for d in wholedata:\n",
    "  r = ''.join([c for c in d['review/text'].lower() if not c in punctuation])\n",
    "  k = r.split()\n",
    "  for i in range(1,len(k)):\n",
    "    wordCount[k[i-1]+' '+k[i]] += 1\n",
    "\n",
    "counts = [(wordCount[w], w) for w in wordCount]\n",
    "counts.sort()\n",
    "counts.reverse()\n",
    "\n",
    "words = [x[1] for x in counts[:1000]]\n",
    "\n",
    "def qwe(dataset):\n",
    "    ### Sentiment analysis\n",
    "\n",
    "    wordId = dict(zip(words, range(len(words))))\n",
    "\n",
    "    def feature(datum):\n",
    "      feat = [0]*len(words)\n",
    "      r = ''.join([c for c in datum['review/text'].lower() if not c in punctuation])\n",
    "      k = r.split()\n",
    "      for i in range(1,len(k)):\n",
    "        if (k[i-1]+' '+k[i]) in words:\n",
    "          feat[wordId[k[i-1]+' '+k[i]]] += 1\n",
    "      feat.append(1) #offset\n",
    "      return feat\n",
    "\n",
    "    X = [feature(d) for d in dataset]\n",
    "    y = [d['review/overall'] for d in dataset]\n",
    "    return X,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,y_train = qwe(training)\n",
    "X_valid,y_valid = qwe(validation)\n",
    "X_test,y_test = qwe(testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4529285368480005\n",
      "0.4526318044571937\n",
      "0.4497842009703396\n",
      "0.42982363119607697\n",
      "0.42097146953442255\n"
     ]
    }
   ],
   "source": [
    "para = [0.01, 0.1, 1, 10, 100]\n",
    "for i in para:\n",
    "    clf = linear_model.Ridge(i, fit_intercept=False)\n",
    "    clf.fit(X_train, y_train)\n",
    "    theta = clf.coef_\n",
    "    predictions = clf.predict(X_valid)\n",
    "    print(mean_squared_error(y_valid, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "#select 100\n",
    "clf = linear_model.Ridge(100, fit_intercept=False)\n",
    "clf.fit(X_train, y_train)\n",
    "theta = clf.coef_\n",
    "predictions = clf.predict(X_test)\n",
    "bi_re_wc = mean_squared_error(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bigrams+ preserve punctuation + wordCount\n",
    "wordCount = defaultdict(int)\n",
    "punctuation = set(string.punctuation)\n",
    "for d in wholedata:\n",
    "  r = ''.join([c for c in d['review/text'].lower()])\n",
    "  k = r.split()\n",
    "  for i in range(1,len(k)):\n",
    "    wordCount[k[i-1]+' '+k[i]] += 1\n",
    "\n",
    "counts = [(wordCount[w], w) for w in wordCount]\n",
    "counts.sort()\n",
    "counts.reverse()\n",
    "\n",
    "words = [x[1] for x in counts[:1000]]\n",
    "\n",
    "def qwe(dataset):\n",
    "    ### Sentiment analysis\n",
    "\n",
    "    wordId = dict(zip(words, range(len(words))))\n",
    "\n",
    "    def feature(datum):\n",
    "      feat = [0]*len(words)\n",
    "      r = ''.join([c for c in datum['review/text'].lower()])\n",
    "      k = r.split()\n",
    "      for i in range(1,len(k)):\n",
    "        if (k[i-1]+' '+k[i]) in words:\n",
    "          feat[wordId[k[i-1]+' '+k[i]]] += 1\n",
    "      feat.append(1) #offset\n",
    "      return feat\n",
    "\n",
    "    X = [feature(d) for d in dataset]\n",
    "    y = [d['review/overall'] for d in dataset]\n",
    "    return X,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,y_train = qwe(training)\n",
    "X_valid,y_valid = qwe(validation)\n",
    "X_test,y_test = qwe(testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.46929095358475725\n",
      "0.4688647062685668\n",
      "0.46483016573941605\n",
      "0.4385983464589267\n",
      "0.42563702854142965\n"
     ]
    }
   ],
   "source": [
    "para = [0.01, 0.1, 1, 10, 100]\n",
    "for i in para:\n",
    "    clf = linear_model.Ridge(i, fit_intercept=False)\n",
    "    clf.fit(X_train, y_train)\n",
    "    theta = clf.coef_\n",
    "    predictions = clf.predict(X_valid)\n",
    "    print(mean_squared_error(y_valid, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "#select 100\n",
    "clf = linear_model.Ridge(100, fit_intercept=False)\n",
    "clf.fit(X_train, y_train)\n",
    "theta = clf.coef_\n",
    "predictions = clf.predict(X_test)\n",
    "bi_pr_wc = mean_squared_error(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = numpy.array([['','preserve_punc','remove_punc'],\n",
    "                ['uni_wordcount',un_pr_wc,un_re_wc],\n",
    "                ['uni_tfidf',un_pr_tfidf,un_re_tfidf],\n",
    "                ['bi_wordcount',bi_pr_wc,bi_re_wc],\n",
    "                ['bi_tfidf',bi_pr_tfidf,bi_re_tfidf]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     preserve_punc          remove_punc\n",
      "uni_wordcount    0.413599935746171  0.38046060252020125\n",
      "uni_tfidf      0.42259774591516014   0.3885811901840076\n",
      "bi_wordcount   0.43219295621818926   0.4243905355380374\n",
      "bi_tfidf        0.4782321775831297   0.4782321775831297\n"
     ]
    }
   ],
   "source": [
    "print(pd.DataFrame(data=result[1:,1:],\n",
    "                  index=result[1:,0],\n",
    "                  columns=result[0,1:]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
